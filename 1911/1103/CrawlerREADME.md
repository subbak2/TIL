# 크롤러

인터넷의 정보를 대신 긁어오는 프로그램입니다. 다양한 방식으로 제작할 수 있는데 Python을 이용하면 손쉽게 크롤러를 만들 수 있습니다. 라이브러리가 잘 구성되어 있기 때문이지요.

- 라이브러리, 프레임워크의 차이?

Python은 크롤러를 위한 도구로만 쓰이기 때문에 대단히 알아야 할 것은 없습니다. 다음 요소만 알면 손쉽게 사용할 수 있습니다.

- if, for 문을 사용할 수 있다.
- dictionary가 뭔지 알고 사용할 수 있다.

### 크롤링의 단계

크롤러는 인터넷의 정보를 대신 긁어오는 프로그램이라고 했습니다. 조금 더 구체적으로 생각해보겠습니다. 인터넷에 있는 정보를 긁어오기 위한 단계는 어떻게 구성될까요?

- 크롤러의 단계 : 정보를 요청하고, 가공하고, 저장한다.
    1. 지정된 경로에 정보를 요청한다.

        네이버에 접속할 때, 우리는 자연스럽게 [www.naver.com](http://www.naver.com) 을 주소 창에 입력합니다. 바로 지정된 주소로 "네이버의 정보를 달라"고 요청하는 것이지요. 마찬가지로 어느 페이지의 정보를 가져올지 정하고, 해당 페이지에 정보를 요청해야 합니다.

    2. 받아온 정보를 잘 꺼내볼 수 있도록 가공한다.

        www.naver.com에 정보를 요청했을 때, 돌려주는 데이터는 완전히 동일하지만 우리가 익숙한 브라우저로 보느냐, 다른 방식으로 요청하느냐에 따라 보이는 방식이 다릅니다. 크롤러로 정보를 가져온 경우, 그에 맞게 정보를 가공하는 과정이 필요합니다.

    3. 원하는 바에 맞게 저장한다.

        대략의 열람만을 하는 경우가 아닌 이상, 크롤러는 대부분 데이터 분석의 전 단계에 해당합니다. 필요한 정보들을 가져와서 목적에 맞는 형태로 저장해야만 필요한 때에 원하는 대로 수집하고 가공한 정보들을 사용할 수 있겠지요.

# Server

클라이언트와 서버는 고객과 은행의 관계로 생각하셔도 좋습니다. 대출을 받는 경우를 가정해보죠. 돈이 은행에 있으니 우리는 은행에 가서 대출을 요청합니다. 그런데 신분증이나 신용 정보도 제대로 갖추지 않은 채 대출을 요청한다면 과연 은행이 요구를 받아줄까요? 대출을 받고 싶다면 고객은 은행이 요구하는 일정 양식을 갖추어야 합니다.

### API

마찬가지로 클라이언트는 서버에 필요한 정보를 요구할 수 있는데, 이때 반드시 지켜야 하는 양식이 있습니다. 이를 서버가 제공하는 API라고 부릅니다. 서버는 클라이언트에게 제공하는 정보의 범위와 그에 필요한 양식을 명확히 요구하고 있는데, 이 스펙을 API라고 부르는 것이죠. 클라이언트가 할 일은 이 요구 사항을 정확히 준수하는 것입니다.

### Flask

원래 서버를 띄우는 일은 간단하지 않습니다. 남들이 들어올 수 있도록 입구를 열고(=소켓을 생성하고 포트 할당), 클라이언트가 보내온 요청을 각 서브 프로그램에 알맞게 할당하는 안내소를 만들어야 합니다.(=Dispatcher Servlet). 이외에 클라이언트가 정확히 요구 사항을 반영했는지 검사하는 과정과, 클라이언트에 돌려주는 정보를 제대로 가공하는 서브 프로그램도 따로 필요하죠.

이 작업은 아주 많이, 정말 많이 발생하는 일입니다. 그리고 자주 만드는 만큼 이미 만들어져 있는 것들을 잘 활용하면 빠르고 간편하게 서버를 만들 수 있는데요. 많은 프레임워크 중에서도 오늘은 Python 기반의 Flask를 이용해 서버를 구축하겠습니다.

### 오늘 할 일

지니 뮤직에서 오늘 날짜의 Top 50 차트를 가져와 순위, 곡명, 아티스트 정보를 뽑아내 DB에 저장합니다.

그 다음에는 적절한 요청이 들어왔을 때 정보를 꺼내 돌려주는 방법에 대해 알아봅니다.

- 실제 코드